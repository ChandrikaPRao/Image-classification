{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set random seed for reproducibility\n",
    "seed = 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train),(X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 59,  62,  63],\n",
       "         [ 43,  46,  45],\n",
       "         [ 50,  48,  43],\n",
       "         ...,\n",
       "         [158, 132, 108],\n",
       "         [152, 125, 102],\n",
       "         [148, 124, 103]],\n",
       "\n",
       "        [[ 16,  20,  20],\n",
       "         [  0,   0,   0],\n",
       "         [ 18,   8,   0],\n",
       "         ...,\n",
       "         [123,  88,  55],\n",
       "         [119,  83,  50],\n",
       "         [122,  87,  57]],\n",
       "\n",
       "        [[ 25,  24,  21],\n",
       "         [ 16,   7,   0],\n",
       "         [ 49,  27,   8],\n",
       "         ...,\n",
       "         [118,  84,  50],\n",
       "         [120,  84,  50],\n",
       "         [109,  73,  42]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[208, 170,  96],\n",
       "         [201, 153,  34],\n",
       "         [198, 161,  26],\n",
       "         ...,\n",
       "         [160, 133,  70],\n",
       "         [ 56,  31,   7],\n",
       "         [ 53,  34,  20]],\n",
       "\n",
       "        [[180, 139,  96],\n",
       "         [173, 123,  42],\n",
       "         [186, 144,  30],\n",
       "         ...,\n",
       "         [184, 148,  94],\n",
       "         [ 97,  62,  34],\n",
       "         [ 83,  53,  34]],\n",
       "\n",
       "        [[177, 144, 116],\n",
       "         [168, 129,  94],\n",
       "         [179, 142,  87],\n",
       "         ...,\n",
       "         [216, 184, 140],\n",
       "         [151, 118,  84],\n",
       "         [123,  92,  72]]],\n",
       "\n",
       "\n",
       "       [[[154, 177, 187],\n",
       "         [126, 137, 136],\n",
       "         [105, 104,  95],\n",
       "         ...,\n",
       "         [ 91,  95,  71],\n",
       "         [ 87,  90,  71],\n",
       "         [ 79,  81,  70]],\n",
       "\n",
       "        [[140, 160, 169],\n",
       "         [145, 153, 154],\n",
       "         [125, 125, 118],\n",
       "         ...,\n",
       "         [ 96,  99,  78],\n",
       "         [ 77,  80,  62],\n",
       "         [ 71,  73,  61]],\n",
       "\n",
       "        [[140, 155, 164],\n",
       "         [139, 146, 149],\n",
       "         [115, 115, 112],\n",
       "         ...,\n",
       "         [ 79,  82,  64],\n",
       "         [ 68,  70,  55],\n",
       "         [ 67,  69,  55]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[175, 167, 166],\n",
       "         [156, 154, 160],\n",
       "         [154, 160, 170],\n",
       "         ...,\n",
       "         [ 42,  34,  36],\n",
       "         [ 61,  53,  57],\n",
       "         [ 93,  83,  91]],\n",
       "\n",
       "        [[165, 154, 128],\n",
       "         [156, 152, 130],\n",
       "         [159, 161, 142],\n",
       "         ...,\n",
       "         [103,  93,  96],\n",
       "         [123, 114, 120],\n",
       "         [131, 121, 131]],\n",
       "\n",
       "        [[163, 148, 120],\n",
       "         [158, 148, 122],\n",
       "         [163, 156, 133],\n",
       "         ...,\n",
       "         [143, 133, 139],\n",
       "         [143, 134, 142],\n",
       "         [143, 133, 144]]],\n",
       "\n",
       "\n",
       "       [[[255, 255, 255],\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         ...,\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         ...,\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[113, 120, 112],\n",
       "         [111, 118, 111],\n",
       "         [105, 112, 106],\n",
       "         ...,\n",
       "         [ 72,  81,  80],\n",
       "         [ 72,  80,  79],\n",
       "         [ 72,  80,  79]],\n",
       "\n",
       "        [[111, 118, 110],\n",
       "         [104, 111, 104],\n",
       "         [ 99, 106,  98],\n",
       "         ...,\n",
       "         [ 68,  75,  73],\n",
       "         [ 70,  76,  75],\n",
       "         [ 78,  84,  82]],\n",
       "\n",
       "        [[106, 113, 105],\n",
       "         [ 99, 106,  98],\n",
       "         [ 95, 102,  94],\n",
       "         ...,\n",
       "         [ 78,  85,  83],\n",
       "         [ 79,  85,  83],\n",
       "         [ 80,  86,  84]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 28,  35,  39],\n",
       "         [ 30,  34,  44],\n",
       "         [ 33,  44,  47],\n",
       "         ...,\n",
       "         [ 43,  56,  45],\n",
       "         [ 52,  64,  53],\n",
       "         [ 46,  58,  47]],\n",
       "\n",
       "        [[ 27,  30,  38],\n",
       "         [ 27,  28,  41],\n",
       "         [ 21,  31,  39],\n",
       "         ...,\n",
       "         [112, 136,  97],\n",
       "         [117, 140, 101],\n",
       "         [115, 138, 100]],\n",
       "\n",
       "        [[ 34,  36,  42],\n",
       "         [ 33,  33,  43],\n",
       "         [ 24,  30,  40],\n",
       "         ...,\n",
       "         [175, 208, 143],\n",
       "         [177, 209, 144],\n",
       "         [176, 208, 143]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[142, 176, 118],\n",
       "         [142, 176, 118],\n",
       "         [150, 184, 127],\n",
       "         ...,\n",
       "         [134, 175, 119],\n",
       "         [128, 168, 112],\n",
       "         [134, 175, 119]],\n",
       "\n",
       "        [[140, 176, 124],\n",
       "         [145, 180, 129],\n",
       "         [150, 186, 134],\n",
       "         ...,\n",
       "         [131, 170, 119],\n",
       "         [130, 170, 119],\n",
       "         [122, 162, 111]],\n",
       "\n",
       "        [[134, 171, 123],\n",
       "         [136, 171, 124],\n",
       "         [136, 171, 124],\n",
       "         ...,\n",
       "         [106, 144, 100],\n",
       "         [104, 142,  99],\n",
       "         [101, 140,  96]]],\n",
       "\n",
       "\n",
       "       [[[134, 186, 223],\n",
       "         [131, 184, 220],\n",
       "         [128, 182, 218],\n",
       "         ...,\n",
       "         [127, 181, 222],\n",
       "         [127, 181, 222],\n",
       "         [128, 182, 223]],\n",
       "\n",
       "        [[133, 189, 228],\n",
       "         [129, 186, 224],\n",
       "         [128, 186, 224],\n",
       "         ...,\n",
       "         [127, 183, 224],\n",
       "         [127, 183, 224],\n",
       "         [128, 184, 225]],\n",
       "\n",
       "        [[128, 185, 226],\n",
       "         [127, 182, 223],\n",
       "         [128, 182, 223],\n",
       "         ...,\n",
       "         [126, 181, 222],\n",
       "         [126, 181, 222],\n",
       "         [126, 180, 221]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[174, 208, 235],\n",
       "         [171, 206, 229],\n",
       "         [155, 189, 216],\n",
       "         ...,\n",
       "         [ 27,  94, 136],\n",
       "         [ 29,  96, 137],\n",
       "         [ 28,  94, 136]],\n",
       "\n",
       "        [[194, 221, 244],\n",
       "         [189, 215, 239],\n",
       "         [159, 196, 225],\n",
       "         ...,\n",
       "         [ 30,  95, 138],\n",
       "         [ 30,  96, 139],\n",
       "         [ 30,  95, 140]],\n",
       "\n",
       "        [[193, 217, 237],\n",
       "         [181, 208, 230],\n",
       "         [168, 201, 227],\n",
       "         ...,\n",
       "         [ 31,  94, 136],\n",
       "         [ 32,  94, 137],\n",
       "         [ 32,  94, 138]]],\n",
       "\n",
       "\n",
       "       [[[125, 125, 116],\n",
       "         [110, 101,  91],\n",
       "         [102,  90,  83],\n",
       "         ...,\n",
       "         [202, 207, 214],\n",
       "         [200, 205, 212],\n",
       "         [202, 208, 214]],\n",
       "\n",
       "        [[142, 146, 142],\n",
       "         [146, 144, 139],\n",
       "         [176, 172, 170],\n",
       "         ...,\n",
       "         [195, 201, 205],\n",
       "         [198, 205, 209],\n",
       "         [204, 211, 215]],\n",
       "\n",
       "        [[180, 185, 183],\n",
       "         [143, 146, 146],\n",
       "         [156, 157, 157],\n",
       "         ...,\n",
       "         [122, 111, 113],\n",
       "         [139, 128, 131],\n",
       "         [158, 147, 150]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[104,  82,  41],\n",
       "         [101,  80,  39],\n",
       "         [101,  81,  38],\n",
       "         ...,\n",
       "         [126, 103,  67],\n",
       "         [126, 103,  69],\n",
       "         [125, 101,  68]],\n",
       "\n",
       "        [[104,  81,  40],\n",
       "         [105,  84,  41],\n",
       "         [109,  88,  43],\n",
       "         ...,\n",
       "         [138, 113,  78],\n",
       "         [137, 113,  80],\n",
       "         [137, 112,  81]],\n",
       "\n",
       "        [[105,  83,  42],\n",
       "         [108,  87,  45],\n",
       "         [115,  94,  50],\n",
       "         ...,\n",
       "         [143, 117,  82],\n",
       "         [143, 116,  84],\n",
       "         [144, 116,  86]]]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the inputs from 0-255 to between 0 and 1 by dividing by 255\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the output values using one-hot encoding\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "class_num = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, (3, 3), input_shape=X_train.shape[1:], padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "    \n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(256, kernel_constraint=maxnorm(3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(128, kernel_constraint=maxnorm(3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(class_num))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "optimizer = 'adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,264,458\n",
      "Trainable params: 2,263,114\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 180s 4ms/step - loss: 1.5007 - accuracy: 0.4653 - val_loss: 1.2325 - val_accuracy: 0.5515\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 179s 4ms/step - loss: 1.0322 - accuracy: 0.6343 - val_loss: 0.8890 - val_accuracy: 0.6855\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 179s 4ms/step - loss: 0.8595 - accuracy: 0.6973 - val_loss: 0.7577 - val_accuracy: 0.7329\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 180s 4ms/step - loss: 0.7681 - accuracy: 0.7297 - val_loss: 0.7536 - val_accuracy: 0.7359\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 179s 4ms/step - loss: 0.7058 - accuracy: 0.7520 - val_loss: 0.6791 - val_accuracy: 0.7619\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 179s 4ms/step - loss: 0.6696 - accuracy: 0.7656 - val_loss: 0.6387 - val_accuracy: 0.7756\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 181s 4ms/step - loss: 0.6287 - accuracy: 0.7801 - val_loss: 0.6509 - val_accuracy: 0.7686\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 180s 4ms/step - loss: 0.5996 - accuracy: 0.7889 - val_loss: 0.6616 - val_accuracy: 0.7661\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 179s 4ms/step - loss: 0.5747 - accuracy: 0.7987 - val_loss: 0.6214 - val_accuracy: 0.7820\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 181s 4ms/step - loss: 0.5539 - accuracy: 0.8039 - val_loss: 0.5983 - val_accuracy: 0.7932\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 181s 4ms/step - loss: 0.5323 - accuracy: 0.8134 - val_loss: 0.5629 - val_accuracy: 0.8050\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 182s 4ms/step - loss: 0.5200 - accuracy: 0.8163 - val_loss: 0.5618 - val_accuracy: 0.8052\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 182s 4ms/step - loss: 0.4984 - accuracy: 0.8244 - val_loss: 0.5561 - val_accuracy: 0.8108\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 179s 4ms/step - loss: 0.4953 - accuracy: 0.8253 - val_loss: 0.5565 - val_accuracy: 0.8078\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 179s 4ms/step - loss: 0.4810 - accuracy: 0.8314 - val_loss: 0.5364 - val_accuracy: 0.8161\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 178s 4ms/step - loss: 0.4736 - accuracy: 0.8355 - val_loss: 0.5621 - val_accuracy: 0.8063\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 181s 4ms/step - loss: 0.4674 - accuracy: 0.8360 - val_loss: 0.5376 - val_accuracy: 0.8173\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 179s 4ms/step - loss: 0.4510 - accuracy: 0.8417 - val_loss: 0.5821 - val_accuracy: 0.8030\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 179s 4ms/step - loss: 0.4475 - accuracy: 0.8436 - val_loss: 0.5247 - val_accuracy: 0.8200\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 181s 4ms/step - loss: 0.4423 - accuracy: 0.8449 - val_loss: 0.5377 - val_accuracy: 0.8170\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 183s 4ms/step - loss: 0.4379 - accuracy: 0.8475 - val_loss: 0.5083 - val_accuracy: 0.8272\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 184s 4ms/step - loss: 0.4284 - accuracy: 0.8478 - val_loss: 0.5510 - val_accuracy: 0.8174\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 181s 4ms/step - loss: 0.4255 - accuracy: 0.8513 - val_loss: 0.5044 - val_accuracy: 0.8243\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 179s 4ms/step - loss: 0.4151 - accuracy: 0.8552 - val_loss: 0.5292 - val_accuracy: 0.8171\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 179s 4ms/step - loss: 0.4149 - accuracy: 0.8545 - val_loss: 0.5550 - val_accuracy: 0.8122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2b9512395f8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.random.seed(seed)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.22%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save('project_model_S1.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
